{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Script per eseguire la grid search sul modello open clip rn50 quickgelu.",
   "id": "67a859b5b127a84c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Questo script serve per far girare il modello senza grid search",
   "id": "f060792725fb052"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T10:14:50.699465Z",
     "start_time": "2025-05-07T10:11:52.181259Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import open_clip\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name=\"RN50\",\n",
    "    pretrained=\"openai\",\n",
    "    device=device\n",
    ")\n",
    "tokenizer = open_clip.get_tokenizer(\"RN50\")\n",
    "\n",
    "# Funzione di utility per caricare le annotazioni\n",
    "def load_annotations(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Dataset \n",
    "class RawMultimodalDataset(Dataset):\n",
    "    def __init__(self, annotations, img_folder, label_encoder):\n",
    "        self.annotations = annotations\n",
    "        self.img_folder = img_folder\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):           \n",
    "        item = self.annotations[idx]\n",
    "        text = item[\"text\"].lower().replace(\"\\n\", \" \").strip()\n",
    "        \n",
    "        # Pulizia del testo\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"\\\\n\", \" \", text).strip() \n",
    "        text = re.sub(r\"\\n\", \" \", text).strip() \n",
    "        text = re.sub(r\"\\\\\", \" \", text).strip() \n",
    "        text = re.sub(r\"  \", \" \", text).strip()\n",
    "        \n",
    "        image_path = os.path.join(self.img_folder, item[\"label\"], item[\"image\"])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.label_encoder.transform([item[\"label\"]])[0]\n",
    "        return text, image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Compute Embeddings \n",
    "def compute_embeddings(dataset):\n",
    "    features, labels = [], []\n",
    "    for text, image, label in tqdm(dataset, desc=\"Computing Embeddings\"):\n",
    "        image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "        text_tokens = tokenizer([text]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img_feat = model.encode_image(image_tensor)\n",
    "            txt_feat = model.encode_text(text_tokens)\n",
    "            img_feat /= img_feat.norm(dim=-1, keepdim=True)\n",
    "            txt_feat /= txt_feat.norm(dim=-1, keepdim=True)\n",
    "            fused = torch.cat([img_feat, txt_feat], dim=-1)  # shape: [1, 2048]\n",
    "\n",
    "        features.append(fused.squeeze(0).cpu())\n",
    "        labels.append(label)\n",
    "\n",
    "    return torch.stack(features), torch.tensor(labels)\n",
    "\n",
    "# Dataset wrapper per le feature pre computate \n",
    "class PrecomputedDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Classificatore \n",
    "class MultimodalClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Training loop \n",
    "def train_classifier(train_loader, val_loader, input_dim, epochs=10, lr=1e-4):\n",
    "    model = MultimodalClassifier(input_dim=input_dim).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                preds = (model(features).squeeze() > 0.5).float()\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "#  Evaluation \n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            preds = (model(features).squeeze() > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Test Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Percorsi ai dati\n",
    "    TRAIN_DATA_DIR = \"../pre_processing/dataset/train/\"\n",
    "    VAL_DATA_DIR = \"../pre_processing/dataset/val/\"\n",
    "    TEST_DATA_DIR = \"../pre_processing/dataset/test/\"\n",
    "    TRAIN_ANNOTATIONS_PATH = '../pre_processing/dataset/train.json'\n",
    "    VAL_ANNOTATIONS_PATH = '../pre_processing/dataset/val.json'\n",
    "    TEST_ANNOTATIONS_PATH = '../pre_processing/dataset/test.json'\n",
    "\n",
    "    train_annotations = load_annotations(TRAIN_ANNOTATIONS_PATH)\n",
    "    val_annotations = load_annotations(VAL_ANNOTATIONS_PATH)\n",
    "    test_annotations = load_annotations(TEST_ANNOTATIONS_PATH)\n",
    "\n",
    "    all_labels = [a[\"label\"] for a in train_annotations + val_annotations + test_annotations]\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_labels)\n",
    "\n",
    "    train_raw = RawMultimodalDataset(train_annotations, TRAIN_DATA_DIR, label_encoder)\n",
    "    val_raw = RawMultimodalDataset(val_annotations, VAL_DATA_DIR, label_encoder)\n",
    "    test_raw = RawMultimodalDataset(test_annotations, TEST_DATA_DIR, label_encoder)\n",
    "\n",
    "    train_features, train_labels = compute_embeddings(train_raw)\n",
    "    val_features, val_labels = compute_embeddings(val_raw)\n",
    "    test_features, test_labels = compute_embeddings(test_raw)\n",
    "\n",
    "    train_dataset = PrecomputedDataset(train_features, train_labels)\n",
    "    val_dataset = PrecomputedDataset(val_features, val_labels)\n",
    "    test_dataset = PrecomputedDataset(test_features, test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "    input_dim = train_features.shape[1]\n",
    "    trained_model = train_classifier(train_loader, val_loader, input_dim=input_dim, epochs=10, lr=1e-3)\n",
    "\n",
    "    evaluate(trained_model, test_loader)\n",
    "\n",
    "    torch.save(trained_model.state_dict(), \"clip_rn50_classifier.pt\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/408M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bd76b0c33e04adb98c6172fd31e2739"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conca\\Documents\\progetti\\progettoNLP\\venv\\lib\\site-packages\\open_clip\\factory.py:388: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n",
      "  warnings.warn(\n",
      "Computing Embeddings: 100%|██████████| 1200/1200 [01:08<00:00, 17.59it/s]\n",
      "Computing Embeddings: 100%|██████████| 150/150 [00:08<00:00, 16.70it/s]\n",
      "Computing Embeddings: 100%|██████████| 300/300 [00:18<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Validation Accuracy: 0.7667\n",
      "Epoch 2/10 - Validation Accuracy: 0.7933\n",
      "Epoch 3/10 - Validation Accuracy: 0.7667\n",
      "Epoch 4/10 - Validation Accuracy: 0.7600\n",
      "Epoch 5/10 - Validation Accuracy: 0.7333\n",
      "Epoch 6/10 - Validation Accuracy: 0.7533\n",
      "Epoch 7/10 - Validation Accuracy: 0.7667\n",
      "Epoch 8/10 - Validation Accuracy: 0.7600\n",
      "Epoch 9/10 - Validation Accuracy: 0.7467\n",
      "Epoch 10/10 - Validation Accuracy: 0.7333\n",
      "Test Accuracy: 0.7900, Precision: 0.7737, Recall: 0.7350, F1: 0.7476\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Questo script esegue invece la grid search e salva i risultati",
   "id": "75778b482a181e70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T14:38:59.642123Z",
     "start_time": "2025-05-07T13:53:35.225907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import open_clip\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "\n",
    "# Setup \n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name=\"RN50-quickgelu\",\n",
    "    pretrained=\"openai\",\n",
    "    device=device\n",
    ")\n",
    "tokenizer = open_clip.get_tokenizer(\"RN50\")\n",
    "\n",
    "# Funzione di utility per caricare le annotazioni\n",
    "def load_annotations(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "# Dataset \n",
    "class RawMultimodalDataset(Dataset):\n",
    "    def __init__(self, annotations, img_folder, label_encoder):\n",
    "        self.annotations = annotations\n",
    "        self.img_folder = img_folder\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.annotations[idx]\n",
    "        text = item[\"text\"].lower()\n",
    "        text = re.sub(r\"\\\\n|\\n|\\\\|\\s+\", \" \", text).strip()\n",
    "\n",
    "        image_path = os.path.join(self.img_folder, item[\"label\"], item[\"image\"])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.label_encoder.transform([item[\"label\"]])[0]\n",
    "        return text, image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def compute_embeddings(dataset):\n",
    "    features, labels = [], []\n",
    "    for text, image, label in tqdm(dataset, desc=\"Computing Embeddings\"):\n",
    "        image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "        text_tokens = tokenizer([text]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img_feat = model.encode_image(image_tensor)\n",
    "            txt_feat = model.encode_text(text_tokens)\n",
    "            img_feat /= img_feat.norm(dim=-1, keepdim=True)\n",
    "            txt_feat /= txt_feat.norm(dim=-1, keepdim=True)\n",
    "            fused = torch.cat([img_feat, txt_feat], dim=-1)\n",
    "\n",
    "        features.append(fused.squeeze(0).cpu())\n",
    "        labels.append(label)\n",
    "\n",
    "    return torch.stack(features), torch.tensor(labels)\n",
    "\n",
    "\n",
    "class PrecomputedDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Classifier \n",
    "class MultimodalClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Evaluation \n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            preds = (model(features).squeeze() > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    TRAIN_DATA_DIR = \"../pre_processing/dataset/train/\"\n",
    "    VAL_DATA_DIR = \"../pre_processing/dataset/val/\"\n",
    "    TEST_DATA_DIR = \"../pre_processing/dataset/test/\"\n",
    "    TRAIN_ANNOTATIONS_PATH = '../pre_processing/dataset/train.json'\n",
    "    VAL_ANNOTATIONS_PATH = '../pre_processing/dataset/val.json'\n",
    "    TEST_ANNOTATIONS_PATH = '../pre_processing/dataset/test.json'\n",
    "\n",
    "    train_annotations = load_annotations(TRAIN_ANNOTATIONS_PATH)\n",
    "    val_annotations = load_annotations(VAL_ANNOTATIONS_PATH)\n",
    "    test_annotations = load_annotations(TEST_ANNOTATIONS_PATH)\n",
    "\n",
    "    all_labels = [a[\"label\"] for a in train_annotations + val_annotations + test_annotations]\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_labels)\n",
    "\n",
    "    train_raw = RawMultimodalDataset(train_annotations, TRAIN_DATA_DIR, label_encoder)\n",
    "    val_raw = RawMultimodalDataset(val_annotations, VAL_DATA_DIR, label_encoder)\n",
    "    test_raw = RawMultimodalDataset(test_annotations, TEST_DATA_DIR, label_encoder)\n",
    "\n",
    "    train_features, train_labels = compute_embeddings(train_raw)\n",
    "    val_features, val_labels = compute_embeddings(val_raw)\n",
    "    test_features, test_labels = compute_embeddings(test_raw)\n",
    "\n",
    "    train_dataset = PrecomputedDataset(train_features, train_labels)\n",
    "    val_dataset = PrecomputedDataset(val_features, val_labels)\n",
    "    test_dataset = PrecomputedDataset(test_features, test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "    input_dim = train_features.shape[1]\n",
    "\n",
    "    dropouts = [0.0, 0.1, 0.2, 0.3]\n",
    "    lrs = [0.01, 0.001, 0.0001]\n",
    "    weight_decays = [0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    schedulers = ['none', 'StepLR', 'LinearLR', 'ExponentialLR', 'CosineAnnealingLR']\n",
    "    unlock_settings = [False, True]\n",
    "    EPOCHS = 10\n",
    "\n",
    "    results_path = \"clip_rn50_grid_results_v3.csv\"\n",
    "    with open(results_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['dropout', 'lr', 'weight_decay', 'scheduler', 'unlocked',\n",
    "                         'val_accuracy', 'val_precision', 'val_recall', 'val_f1',\n",
    "                         'test_accuracy', 'test_precision', 'test_recall', 'test_f1'])\n",
    "\n",
    "\n",
    "    combinations = list(product(dropouts, lrs, weight_decays, schedulers, unlock_settings))\n",
    "    for dropout, lr, wd, sched_name, unlock in tqdm(combinations, desc=\"Grid Search\", leave=True):\n",
    "        model = MultimodalClassifier(input_dim=input_dim, dropout=dropout).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        if sched_name == 'StepLR':\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "        elif sched_name == 'LinearLR':\n",
    "            scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.9, total_iters=EPOCHS)\n",
    "        elif sched_name == 'ExponentialLR':\n",
    "            scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "        elif sched_name == 'CosineAnnealingLR':\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        else:\n",
    "            scheduler = None\n",
    "            \n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "            \n",
    "        if unlock:\n",
    "            #clip_model = CLIPModel.from_pretrained(NOME_DEL_MODELLO_PRETRAINED).to(DEVICE)\n",
    "            clip_model, _, preprocess_temp =  open_clip.create_model_and_transforms(\n",
    "                model_name=\"RN50-quickgelu\",\n",
    "                pretrained=\"openai\",\n",
    "                device=device\n",
    "            )\n",
    "            clip_model.train()\n",
    "        \n",
    "            for param in clip_model.parameters():\n",
    "                param.requires_grad = False  # Freeza tutto\n",
    "                \n",
    "            # Visual: sblocca layer4 della ResNet\n",
    "            for name, param in clip_model.visual.named_parameters():\n",
    "                param.requires_grad = \"layer4\" in name or \"attnpool\" in name\n",
    "        \n",
    "            # Text: sblocca ultimi 3 transformer block\n",
    "            for name, param in clip_model.transformer.named_parameters():\n",
    "                param.requires_grad = any(f\"resblocks.{i}.\" in name for i in [9, 10, 11])\n",
    "        \n",
    "            # Fusione finale: sblocca projection e logit scale\n",
    "            for name, param in clip_model.named_parameters():\n",
    "                if any(k in name for k in [\"text_projection\", \"logit_scale\"]):\n",
    "                    param.requires_grad = True\n",
    "            \n",
    "\n",
    "        for epoch in range(10):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for features, labels in train_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            train_losses.append(epoch_loss / len(train_loader))\n",
    "            \n",
    "            \n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for features, labels in val_loader:\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    logits = model(features).squeeze()\n",
    "                    loss = criterion(logits, labels)\n",
    "                    val_loss += loss.item()\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            \n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "        val_metrics = evaluate(model, val_loader)\n",
    "        test_metrics = evaluate(model, test_loader)\n",
    "\n",
    "        # with open(results_path, 'a') as f:\n",
    "        #     f.write(f\"{dropout},{lr},{wd},{sched_name},{','.join(map(str, val_metrics))},{','.join(map(str, test_metrics))}\\n\")\n",
    "            \n",
    "        with open(results_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            #f.write(\"dropout,lr,weight_decay,scheduler,unlock,val_acc,val_prec,val_rec,val_f1,test_acc,test_prec,test_rec,test_f1\\n\")\n",
    "            writer.writerow([dropout, lr, wd, sched_name, unlock, *val_metrics, *test_metrics])\n",
    "            \n",
    "\n",
    "        #model_name = f\"./saves_model2.2/clip_rn50_d{dropout}_lr{lr}_wd{wd}_sched{sched_name}.pt\"\n",
    "        safe_model_name = \"openai_rn50\"\n",
    "        model_name = f\"./saves_model2.2/{safe_model_name}_drop{dropout}_lrs{lr}_weights_{wd}_sched_{sched_name}_unlock{unlock}_augmented\"\n",
    "        #torch.save(model.state_dict(), model_name)\n",
    "        #Salvo anche immagine\n",
    "        # Save loss plot\n",
    "        plt.figure()\n",
    "        plt.plot(train_losses, label=\"Train Loss\")\n",
    "        plt.plot(val_losses, label=\"Val Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(f\"Loss Curve - {model_name}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f\"{model_name}_loss_curve.png\")\n",
    "        plt.close()\n"
   ],
   "id": "64929202e4f707df",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Embeddings: 100%|██████████| 1200/1200 [00:52<00:00, 22.96it/s]\n",
      "Computing Embeddings: 100%|██████████| 150/150 [00:06<00:00, 21.51it/s]\n",
      "Computing Embeddings: 100%|██████████| 300/300 [00:15<00:00, 19.64it/s]\n",
      "Grid Search: 100%|██████████| 720/720 [44:07<00:00,  3.68s/it]  \n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
